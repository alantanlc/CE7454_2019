{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01 : MNIST multi-layer -- demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import time\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import check_mnist_dataset_exists\n",
    "data_path = check_mnist_dataset_exists()\n",
    "\n",
    "train_data = torch.load(data_path+'mnist/train_data.pt')\n",
    "train_label = torch.load(data_path+'mnist/train_label.pt')\n",
    "test_data = torch.load(data_path+'mnist/test_data.pt')\n",
    "test_label = torch.load(data_path+'mnist/test_label.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a two layer net class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class two_layer_net(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(two_layer_net, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(input_size, hidden_size, bias = False)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size, bias = False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.layer1(x)\n",
    "        y_hat = F.relu(y)\n",
    "        scores = self.layer2(y_hat)\n",
    "        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the net (recall that a one layer net had 7840 parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_layer_net(\n",
      "  (layer1): Linear(in_features=784, out_features=50, bias=False)\n",
      "  (layer2): Linear(in_features=50, out_features=10, bias=False)\n",
      ")\n",
      "There are 39700 (0.04 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "net = two_layer_net(784,50,10)\n",
    "\n",
    "print(net)\n",
    "utils.display_num_param(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the criterion, optimizer, batchsize, learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.01)\n",
    "\n",
    "bs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test_set():\n",
    "    \n",
    "    running_error = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for i in range(0, 10000, bs):\n",
    "        \n",
    "        minibatch_data = test_data[i:i+bs]\n",
    "        minibatch_label = test_label[i:i+bs]\n",
    "        \n",
    "        inputs = minibatch_data.view(bs, 784)\n",
    "        \n",
    "        scores = net(inputs)\n",
    "        \n",
    "        error = utils.get_error(scores.detach(), minibatch_label)\n",
    "        \n",
    "        running_error += error.item()\n",
    "        \n",
    "        num_batches += 1\n",
    "        \n",
    "    total_error = running_error / num_batches\n",
    "    print('test error = ', total_error * 100, 'percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "epoch= 0 \t time= 3.0836031436920166 \t loss= 0.696904651624461 \t error= 16.731666855017345 percent\n",
      "test error =  9.870000433921813 percent\n",
      " \n",
      "epoch= 5 \t time= 13.714733839035034 \t loss= 0.2118002499345069 \t error= 5.935000711679458 percent\n",
      "test error =  5.770000576972961 percent\n",
      " \n",
      "epoch= 10 \t time= 27.618032217025757 \t loss= 0.15499164517239358 \t error= 4.320000716050465 percent\n",
      "test error =  4.520000576972961 percent\n",
      " \n",
      "epoch= 15 \t time= 39.64015460014343 \t loss= 0.12130829802015797 \t error= 3.333333977063497 percent\n",
      "test error =  3.780000555515289 percent\n",
      " \n",
      "epoch= 20 \t time= 51.49605965614319 \t loss= 0.09989201838352407 \t error= 2.791667240858078 percent\n",
      "test error =  3.190000534057617 percent\n",
      " \n",
      "epoch= 25 \t time= 63.23140573501587 \t loss= 0.08511769453141217 \t error= 2.3650004943211873 percent\n",
      "test error =  3.01000052690506 percent\n",
      " \n",
      "epoch= 30 \t time= 75.00600528717041 \t loss= 0.07412115502830906 \t error= 2.0866671164830524 percent\n",
      "test error =  2.790000522136688 percent\n",
      " \n",
      "epoch= 35 \t time= 86.78487491607666 \t loss= 0.06529838233398429 \t error= 1.8100004076957703 percent\n",
      "test error =  2.660000503063202 percent\n",
      " \n",
      "epoch= 40 \t time= 99.3031280040741 \t loss= 0.05844673596097467 \t error= 1.6150003612041473 percent\n",
      "test error =  2.5600004911422727 percent\n",
      " \n",
      "epoch= 45 \t time= 110.53628134727478 \t loss= 0.052689205900630136 \t error= 1.4416669984658559 percent\n",
      "test error =  2.500000464916229 percent\n",
      " \n",
      "epoch= 50 \t time= 122.99217748641968 \t loss= 0.047652407531354884 \t error= 1.288333628575007 percent\n",
      "test error =  2.47000048160553 percent\n",
      " \n",
      "epoch= 55 \t time= 136.6968879699707 \t loss= 0.043213349847957334 \t error= 1.1300002654393513 percent\n",
      "test error =  2.460000479221344 percent\n",
      " \n",
      "epoch= 60 \t time= 146.6711573600769 \t loss= 0.03933634339662967 \t error= 1.0400002380212148 percent\n",
      "test error =  2.5400004982948303 percent\n",
      " \n",
      "epoch= 65 \t time= 156.0489296913147 \t loss= 0.03598943828557579 \t error= 0.9133335491021475 percent\n",
      "test error =  2.5600004911422727 percent\n",
      " \n",
      "epoch= 70 \t time= 165.12332272529602 \t loss= 0.032869929121841175 \t error= 0.8133335252602896 percent\n",
      "test error =  2.5200004816055297 percent\n",
      " \n",
      "epoch= 75 \t time= 175.44783449172974 \t loss= 0.030288710538913924 \t error= 0.7233335018157959 percent\n",
      "test error =  2.59000049829483 percent\n",
      " \n",
      "epoch= 80 \t time= 187.77270984649658 \t loss= 0.027994356940990353 \t error= 0.6750001589457194 percent\n",
      "test error =  2.600000464916229 percent\n",
      " \n",
      "epoch= 85 \t time= 199.54241728782654 \t loss= 0.02571006612801769 \t error= 0.5600001335144043 percent\n",
      "test error =  2.57000048160553 percent\n",
      " \n",
      "epoch= 90 \t time= 212.40649008750916 \t loss= 0.023776315088301393 \t error= 0.5050001204013824 percent\n",
      "test error =  2.610000479221344 percent\n",
      " \n",
      "epoch= 95 \t time= 224.0144968032837 \t loss= 0.02204487460562086 \t error= 0.4750001132488251 percent\n",
      "test error =  2.5400004982948303 percent\n",
      " \n",
      "epoch= 100 \t time= 234.90756464004517 \t loss= 0.020445902079671213 \t error= 0.3900000929832459 percent\n",
      "test error =  2.5900004863739015 percent\n",
      " \n",
      "epoch= 105 \t time= 244.07509446144104 \t loss= 0.018862708427625573 \t error= 0.35666674971580503 percent\n",
      "test error =  2.560000503063202 percent\n",
      " \n",
      "epoch= 110 \t time= 253.8781316280365 \t loss= 0.01748618985468056 \t error= 0.286666735013326 percent\n",
      "test error =  2.6900004982948302 percent\n",
      " \n",
      "epoch= 115 \t time= 264.5885102748871 \t loss= 0.016409985237433526 \t error= 0.27833339969317117 percent\n",
      "test error =  2.600000488758087 percent\n",
      " \n",
      "epoch= 120 \t time= 274.79086685180664 \t loss= 0.015348600504833181 \t error= 0.22666672070821128 percent\n",
      "test error =  2.6000005245208744 percent\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(200):\n",
    "    \n",
    "    running_error = 0\n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    shuffled_indices = torch.randperm(60000)\n",
    "    \n",
    "    for count in range(0, 60000, bs):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        indices = shuffled_indices[count:count+bs]\n",
    "        minibatch_data = train_data[indices]\n",
    "        minibatch_label = train_label[indices]\n",
    "        \n",
    "        inputs = minibatch_data.view(bs, 784)\n",
    "        \n",
    "        inputs.requires_grad_()\n",
    "        \n",
    "        scores = net(inputs)\n",
    "        \n",
    "        loss = criterion(scores, minibatch_label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # compute some stats\n",
    "        \n",
    "        running_loss += loss.detach().item()\n",
    "        \n",
    "        error = utils.get_error(scores.detach(), minibatch_label)\n",
    "        running_error += error.item()\n",
    "        \n",
    "        num_batches += 1\n",
    "        \n",
    "    # once the epoch is finished we divide the \"running quantities\"\n",
    "    # by the number of batches\n",
    "    \n",
    "    total_loss = running_loss / num_batches\n",
    "    total_error = running_error / num_batches\n",
    "    elapsed_time = time.time() - start\n",
    "    \n",
    "    # every 10 epoch we display the stats\n",
    "    # and compute the error rate on the test set\n",
    "    \n",
    "    if epoch % 5 == 0 :\n",
    "        \n",
    "        print(' ')\n",
    "        \n",
    "        print('epoch=', epoch, '\\t time=', elapsed_time, '\\t loss=', total_loss, '\\t error=', total_error*100, 'percent')\n",
    "        \n",
    "        eval_on_test_set()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
