{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 03 : LeNet5 architecture - exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    file_name = 'lenet5_exercise.ipynb'\n",
    "    import subprocess\n",
    "    path_to_file = subprocess.check_output('find . -type f -name ' + str(file_name), shell=True).decode(\"utf-8\")\n",
    "    print(path_to_file)\n",
    "    path_to_file = path_to_file.replace(file_name,\"\").replace('\\n',\"\")\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With or without GPU?\n",
    "\n",
    "It is recommended to run this code on GPU:<br> \n",
    "* Time for 1 epoch on CPU : 96 sec (1.62 min)<br> \n",
    "* Time for 1 epoch on GPU : 2 sec w/ GeForce GTX 1080 Ti <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# device= torch.device(\"cuda\")\n",
    "device= torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the MNIST dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "from utils import check_mnist_dataset_exists\n",
    "data_path=check_mnist_dataset_exists()\n",
    "\n",
    "train_data=torch.load(data_path+'mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'mnist/train_label.pt')\n",
    "test_data=torch.load(data_path+'mnist/test_data.pt')\n",
    "test_label=torch.load(data_path+'mnist/test_label.pt')\n",
    "\n",
    "print(train_data.size())\n",
    "print(test_data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute average pixel intensity over all training set and all channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1306)\n"
     ]
    }
   ],
   "source": [
    "mean= train_data.mean()\n",
    "\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3081)\n"
     ]
    }
   ],
   "source": [
    "std= train_data.std()\n",
    "\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a LeNet5 convnet class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5_convnet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(LeNet5_convnet, self).__init__()\n",
    "\n",
    "        # CL1:   28 x 28  -->    50 x 28 x 28 \n",
    "        self.conv1 = nn.Conv2d(1,   50,  kernel_size=3,  padding=1 )\n",
    "        \n",
    "        # MP1: 50 x 28 x 28 -->    50 x 14 x 14\n",
    "        self.pool1  = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # CL2:   50 x 14 x 14  -->    100 x 14 x 14 \n",
    "        self.conv2 = nn.Conv2d(50, 100, kernel_size=3, padding=1 )\n",
    "        \n",
    "        # MP2: 100 x 14 x 14 -->    100 x 7 x 7\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # LL1:   100 x 7 x 7 = 4900 -->  100 \n",
    "        self.linear1 = nn.Linear(4900, 100, bias = True)\n",
    "        \n",
    "        # LL2:   100  -->  10 \n",
    "        self.linear2 = nn.Linear(100, 10, bias = True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # CL1:   28 x 28  -->    50 x 28 x 28 \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # MP1: 50 x 28 x 28 -->    50 x 14 x 14\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # CL2:   50 x 14 x 14  -->    100 x 14 x 14\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # MP2: 100 x 14 x 14 -->    100 x 7 x 7\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # LL1:   100 x 7 x 7 = 4900  -->  100 \n",
    "        x = x.view(-1, 4900) # python will automatically fix the value -1, otherwise we can also put the value of bs for the first parameter\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # LL2:   4900  -->  10 \n",
    "        x = self.linear2(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the net. How many parameters in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5_convnet(\n",
      "  (conv1): Conv2d(1, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(50, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear1): Linear(in_features=4900, out_features=100, bias=True)\n",
      "  (linear2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "There are 536710 (0.54 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "net=LeNet5_convnet()\n",
    "print(net)\n",
    "utils.display_num_param(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send the weights of the networks to the GPU (as well as the mean and std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)\n",
    "\n",
    "mean=mean.to(device)\n",
    "\n",
    "std=std.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the criterion, batch size, and initial learning rate. Select the following:\n",
    "* batch size =128\n",
    "* initial learning rate =0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "my_lr=0.25\n",
    "\n",
    "bs=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to evaluate the network on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test_set():\n",
    "\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "\n",
    "    for i in range(0,10000,bs):\n",
    "\n",
    "        minibatch_data =  test_data[i:i+bs].unsqueeze(dim=1)\n",
    "        minibatch_label= test_label[i:i+bs]\n",
    "\n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        inputs = (minibatch_data - mean)/std    \n",
    "\n",
    "        scores=net( inputs ) \n",
    "\n",
    "        error = utils.get_error( scores , minibatch_label)\n",
    "\n",
    "        running_error += error.item()\n",
    "\n",
    "        num_batches+=1\n",
    "\n",
    "\n",
    "    total_error = running_error/num_batches\n",
    "    print( 'error rate on test set =', total_error*100 ,'percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do 30 passes through the training set. Divide the learning rate by 2 every 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 \t time= 2.0008997082710267 min \t lr= 0.25 \t loss= 0.38533726749993336 \t error= 12.375066631130064 percent\n",
      "error rate on test set = 3.0755537974683547 percent\n",
      " \n",
      "epoch= 2 \t time= 4.01051664352417 min \t lr= 0.25 \t loss= 0.05801497088439429 \t error= 1.7846037711161795 percent\n",
      "error rate on test set = 1.4833860759493671 percent\n",
      " \n",
      "epoch= 3 \t time= 5.715375864505768 min \t lr= 0.25 \t loss= 0.03815688563189082 \t error= 1.210465525259087 percent\n",
      "error rate on test set = 1.4833860759493671 percent\n",
      " \n",
      "epoch= 4 \t time= 7.480000046888987 min \t lr= 0.25 \t loss= 0.0294633902160566 \t error= 0.9594882729211088 percent\n",
      "error rate on test set = 0.949367088607595 percent\n",
      " \n",
      "epoch= 5 \t time= 9.572719752788544 min \t lr= 0.125 \t loss= 0.016897272537656025 \t error= 0.498067697228145 percent\n",
      "error rate on test set = 0.870253164556962 percent\n",
      " \n",
      "epoch= 6 \t time= 11.504325397809346 min \t lr= 0.125 \t loss= 0.013420055948023094 \t error= 0.3714685501066098 percent\n",
      "error rate on test set = 0.9098101265822784 percent\n",
      " \n",
      "epoch= 7 \t time= 13.424442088603973 min \t lr= 0.125 \t loss= 0.01158681887938931 \t error= 0.3270478009669257 percent\n",
      "error rate on test set = 0.9691455696202531 percent\n",
      " \n",
      "epoch= 8 \t time= 15.51608958641688 min \t lr= 0.125 \t loss= 0.00963154078797196 \t error= 0.25708511439976156 percent\n",
      "error rate on test set = 0.949367088607595 percent\n",
      " \n",
      "epoch= 9 \t time= 17.524791049957276 min \t lr= 0.125 \t loss= 0.008346688764927257 \t error= 0.22987739872068227 percent\n",
      "error rate on test set = 0.9098101265822784 percent\n",
      " \n",
      "epoch= 10 \t time= 19.518886323769888 min \t lr= 0.0625 \t loss= 0.005317620127612024 \t error= 0.11382818476223487 percent\n",
      "error rate on test set = 0.8306962025316454 percent\n",
      " \n",
      "epoch= 11 \t time= 21.654669320583345 min \t lr= 0.0625 \t loss= 0.004520155573467305 \t error= 0.09828091684434968 percent\n",
      "error rate on test set = 0.8900316455696203 percent\n",
      " \n",
      "epoch= 12 \t time= 23.659747338294984 min \t lr= 0.0625 \t loss= 0.0040846920874367445 \t error= 0.08550995448504939 percent\n",
      "error rate on test set = 0.8208069620253164 percent\n",
      " \n",
      "epoch= 13 \t time= 25.944102915128074 min \t lr= 0.0625 \t loss= 0.0036610448297966064 \t error= 0.06496535181236673 percent\n",
      "error rate on test set = 0.860363924050633 percent\n",
      " \n",
      "epoch= 14 \t time= 28.118248812357585 min \t lr= 0.0625 \t loss= 0.003309987536224133 \t error= 0.056636460554371 percent\n",
      "error rate on test set = 0.9098101265822784 percent\n",
      " \n",
      "epoch= 15 \t time= 30.16413340965907 min \t lr= 0.03125 \t loss= 0.0027398259200111428 \t error= 0.04331023454157783 percent\n",
      "error rate on test set = 0.8999208860759493 percent\n",
      " \n",
      "epoch= 16 \t time= 32.1859539826711 min \t lr= 0.03125 \t loss= 0.0025840571550531997 \t error= 0.03997867803837953 percent\n",
      "error rate on test set = 0.8999208860759493 percent\n",
      " \n",
      "epoch= 17 \t time= 34.29458381732305 min \t lr= 0.03125 \t loss= 0.0024408680110510044 \t error= 0.02998400852878465 percent\n",
      "error rate on test set = 0.8900316455696203 percent\n",
      " \n",
      "epoch= 18 \t time= 36.35972887277603 min \t lr= 0.03125 \t loss= 0.0023010620622053446 \t error= 0.034981343283582086 percent\n",
      "error rate on test set = 0.9098101265822784 percent\n",
      " \n",
      "epoch= 19 \t time= 38.33852840662003 min \t lr= 0.03125 \t loss= 0.0022142084271375606 \t error= 0.0316497867803838 percent\n",
      "error rate on test set = 0.8900316455696203 percent\n",
      " \n",
      "epoch= 20 \t time= 40.3716105779012 min \t lr= 0.015625 \t loss= 0.002016159409520227 \t error= 0.025541937427480083 percent\n",
      "error rate on test set = 0.9098101265822784 percent\n",
      " \n",
      "epoch= 21 \t time= 42.46583586533864 min \t lr= 0.015625 \t loss= 0.001957417958444311 \t error= 0.023320895522388058 percent\n",
      "error rate on test set = 0.8999208860759493 percent\n",
      " \n",
      "epoch= 22 \t time= 44.43494576215744 min \t lr= 0.015625 \t loss= 0.0018973921540969942 \t error= 0.023320895522388058 percent\n",
      "error rate on test set = 0.8999208860759493 percent\n",
      " \n",
      "epoch= 23 \t time= 46.43855699300766 min \t lr= 0.015625 \t loss= 0.0018526019362603942 \t error= 0.02498667377398721 percent\n",
      "error rate on test set = 0.8999208860759493 percent\n",
      " \n",
      "epoch= 24 \t time= 48.408166309197746 min \t lr= 0.015625 \t loss= 0.001814017378662622 \t error= 0.021655117270788914 percent\n",
      "error rate on test set = 0.8900316455696203 percent\n",
      " \n",
      "epoch= 25 \t time= 50.14872421820959 min \t lr= 0.0078125 \t loss= 0.0017319197150058737 \t error= 0.019989339019189766 percent\n",
      "error rate on test set = 0.8900316455696203 percent\n",
      " \n",
      "epoch= 26 \t time= 51.84495870669683 min \t lr= 0.0078125 \t loss= 0.001707622389064332 \t error= 0.01832356076759062 percent\n",
      "error rate on test set = 0.8900316455696203 percent\n",
      " \n",
      "epoch= 27 \t time= 53.54472943941752 min \t lr= 0.0078125 \t loss= 0.0016884131142813122 \t error= 0.021655117270788914 percent\n",
      "error rate on test set = 0.8999208860759493 percent\n",
      " \n",
      "epoch= 28 \t time= 55.35169785022735 min \t lr= 0.0078125 \t loss= 0.0016676709670013115 \t error= 0.023320895522388058 percent\n",
      "error rate on test set = 0.8999208860759493 percent\n",
      " \n",
      "epoch= 29 \t time= 57.355684490998584 min \t lr= 0.0078125 \t loss= 0.0016482962352201169 \t error= 0.021655117270788914 percent\n",
      "error rate on test set = 0.8900316455696203 percent\n",
      " \n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "for epoch in range(1,30):\n",
    "    \n",
    "    if not epoch%5:\n",
    "        my_lr = my_lr / 2\n",
    "        \n",
    "    optimizer=torch.optim.SGD( net.parameters() , lr=my_lr )\n",
    "        \n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    \n",
    "    shuffled_indices=torch.randperm(60000)\n",
    " \n",
    "    for count in range(0,60000,bs):\n",
    "        \n",
    "        # FORWARD AND BACKWARD PASS\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "             \n",
    "        indices=shuffled_indices[count:count+bs]\n",
    "        minibatch_data =  train_data[indices].unsqueeze(dim=1)\n",
    "        minibatch_label=  train_label[indices]\n",
    "        \n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        inputs = (minibatch_data - mean)/std      \n",
    "        \n",
    "        inputs.requires_grad_()\n",
    "\n",
    "        scores=net( inputs ) \n",
    "\n",
    "        loss =  criterion( scores , minibatch_label) \n",
    "          \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # COMPUTE STATS\n",
    "        \n",
    "        running_loss += loss.detach().item()\n",
    "        \n",
    "        error = utils.get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "        \n",
    "        num_batches+=1        \n",
    "    \n",
    "    \n",
    "    # AVERAGE STATS THEN DISPLAY\n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    elapsed = (time.time()-start)/60\n",
    "    \n",
    "    print('epoch=',epoch, '\\t time=', elapsed,'min', '\\t lr=', my_lr  ,'\\t loss=', total_loss , '\\t error=', total_error*100 ,'percent')\n",
    "    eval_on_test_set() \n",
    "    print(' ')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose image at random from the test set and see how good/bad are the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a picture at random\n",
    "idx=randint(0, 10000-1)\n",
    "im=test_data[idx]\n",
    "\n",
    "# diplay the picture\n",
    "utils.show(im)\n",
    "\n",
    "# send to device, rescale, and view as a batch of 1 \n",
    "im = im.to(device)\n",
    "im= (im-mean) / std\n",
    "im=im.view(1,28,28).unsqueeze(dim=1)\n",
    "\n",
    "# feed it to the net and display the confidence scores\n",
    "scores =  net(im) \n",
    "probs= F.softmax(scores, dim=1)\n",
    "utils.show_prob_mnist(probs.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
