{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 03 : LeNet5 architecture - exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With or without GPU?\n",
    "It is recommended to run this code on GPU:\n",
    "- Time for 1 epoch on CPU: 96 sec (1.62 min)\n",
    "- Time for 1 epoch on GPU: 2 sec w/ GeForce GTX 1080 Ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "from utils import check_mnist_dataset_exists\n",
    "data_path=check_mnist_dataset_exists()\n",
    "\n",
    "train_data=torch.load(data_path+'mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'mnist/train_label.pt')\n",
    "test_data=torch.load(data_path+'mnist/test_data.pt')\n",
    "test_label=torch.load(data_path+'mnist/test_label.pt')\n",
    "\n",
    "print(train_data.size())\n",
    "print(test_data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute average pixel intensity over all training set and all channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1306)\n"
     ]
    }
   ],
   "source": [
    "mean = train_data.mean()\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3081)\n"
     ]
    }
   ],
   "source": [
    "std = train_data.std()\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a LeNet5 convnet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5_convnet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(LeNet5_convnet, self).__init__()\n",
    "    \n",
    "        # CL1: 1 x 28 x 28 --> 50 x 28 x 28\n",
    "        self.conv1 = nn.Conv2d(1, 50, kernel_size = 3, padding = 1)\n",
    "\n",
    "        # MP1: 50 x 28 x 28 --> 50 x 14 x 14\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # CL2: 50 x 14 x 14 --> 100 x 14 x 14\n",
    "        self.conv2 = nn.Conv2d(50, 100, kernel_size = 3, padding = 1)\n",
    "\n",
    "        # MP2: 100 x 14 x 14 --> 100 x 7 x 7\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # LL1: 100 x 7 x 7 = 4900 --> 100\n",
    "        self.linear1 = nn.Linear(4900, 100)\n",
    "\n",
    "        # LL2: 100 --> 10\n",
    "        self.linear2 = nn.Linear(100, 10, bias = True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = x.view(-1, 4900)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5_convnet(\n",
      "  (conv1): Conv2d(1, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(50, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear1): Linear(in_features=4900, out_features=100, bias=True)\n",
      "  (linear2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "There are 536710 (0.54 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "net = LeNet5_convnet()\n",
    "print(net)\n",
    "utils.display_num_param(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send the weights of the networks to the GPU (as well as the mean and std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)\n",
    "\n",
    "mean = mean.to(device)\n",
    "\n",
    "std = std.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the criterion, batch size, and initial learning rate. Select the following:\n",
    "- batch size = 128\n",
    "- initial learning rate = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "my_lr = 0.25\n",
    "\n",
    "bs = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to evalate the network on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test_set():\n",
    "    \n",
    "    running_error = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for i in range(0, 10000, bs):\n",
    "        \n",
    "        minibatch_data = test_data[i:i+bs].unsqueeze(dim=1)\n",
    "        minibatch_label = test_label[i:i+bs]\n",
    "        \n",
    "        minibatch_data = minibatch_data.to(device)\n",
    "        minibatch_label = minibatch_label.to(device)\n",
    "        \n",
    "        inputs = (minibatch_data - mean) / std\n",
    "        \n",
    "        scores = net(inputs)\n",
    "        \n",
    "        error = utils.get_error(scores, minibatch_label)\n",
    "        \n",
    "        running_error += error.item()\n",
    "        \n",
    "        num_batches += 1\n",
    "        \n",
    "    total_error = running_error / num_batches\n",
    "    print('error rate on test set = ', total_error * 100, 'percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do 30 passes through the training set. Divide the learning rate by 2 every 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 \t time= 2.01674386660258 min \t lr= 0.25 \t loss= 0.2685899446422516 \t error= 8.598192071101304 percent\n",
      "error rate on test set =  2.2844145569620253 percent\n",
      " \n",
      "epoch= 2 \t time= 4.037270088990529 min \t lr= 0.25 \t loss= 0.05859391000181405 \t error= 1.7712775451033864 percent\n",
      "error rate on test set =  1.3844936708860758 percent\n",
      " \n",
      "epoch= 3 \t time= 6.124068915843964 min \t lr= 0.25 \t loss= 0.034963075733080363 \t error= 1.0927505330490406 percent\n",
      "error rate on test set =  1.1075949367088607 percent\n",
      " \n",
      "epoch= 4 \t time= 8.068228793144225 min \t lr= 0.25 \t loss= 0.02596571209489493 \t error= 0.8317786112014672 percent\n",
      "error rate on test set =  1.0284810126582278 percent\n",
      " \n",
      "epoch= 5 \t time= 10.053762833277384 min \t lr= 0.125 \t loss= 0.014445360574095862 \t error= 0.42810501066098083 percent\n",
      "error rate on test set =  0.7911392405063291 percent\n",
      " \n",
      "epoch= 6 \t time= 12.027889955043793 min \t lr= 0.125 \t loss= 0.01103264417736106 \t error= 0.3059479346407502 percent\n",
      "error rate on test set =  1.0977056962025316 percent\n",
      " \n",
      "epoch= 7 \t time= 13.980446072419484 min \t lr= 0.125 \t loss= 0.008871913455315739 \t error= 0.25652985074626866 percent\n",
      "error rate on test set =  0.78125 percent\n",
      " \n",
      "epoch= 8 \t time= 15.887998867034913 min \t lr= 0.125 \t loss= 0.007432735844779371 \t error= 0.18712242783259736 percent\n",
      "error rate on test set =  0.8109177215189873 percent\n",
      " \n",
      "epoch= 9 \t time= 17.808677212397257 min \t lr= 0.125 \t loss= 0.005963437849511656 \t error= 0.14992004264392325 percent\n",
      "error rate on test set =  0.78125 percent\n",
      " \n",
      "epoch= 10 \t time= 19.749708342552186 min \t lr= 0.0625 \t loss= 0.004121461434637694 \t error= 0.07995735607675906 percent\n",
      "error rate on test set =  0.7614715189873418 percent\n",
      " \n",
      "epoch= 11 \t time= 21.683022554715475 min \t lr= 0.0625 \t loss= 0.0035570684619758504 \t error= 0.061633795309168446 percent\n",
      "error rate on test set =  0.7416930379746836 percent\n",
      " \n",
      "epoch= 12 \t time= 23.64396144549052 min \t lr= 0.0625 \t loss= 0.0031606906051009666 \t error= 0.053304904051172705 percent\n",
      "error rate on test set =  0.7120253164556962 percent\n",
      " \n",
      "epoch= 13 \t time= 25.631424089272816 min \t lr= 0.0625 \t loss= 0.002850476133870985 \t error= 0.04331023454157783 percent\n",
      "error rate on test set =  0.7318037974683544 percent\n",
      " \n",
      "epoch= 14 \t time= 27.65960694948832 min \t lr= 0.0625 \t loss= 0.0025693493012530254 \t error= 0.03664712153518124 percent\n",
      "error rate on test set =  0.7614715189873418 percent\n",
      " \n",
      "epoch= 15 \t time= 29.773135256767272 min \t lr= 0.03125 \t loss= 0.002158908177925366 \t error= 0.02498667377398721 percent\n",
      "error rate on test set =  0.7713607594936709 percent\n",
      " \n",
      "epoch= 16 \t time= 31.805681570370993 min \t lr= 0.03125 \t loss= 0.0020210844629697613 \t error= 0.023320895522388058 percent\n",
      "error rate on test set =  0.7713607594936709 percent\n",
      " \n",
      "epoch= 17 \t time= 33.908922561009724 min \t lr= 0.03125 \t loss= 0.0019402965294645985 \t error= 0.0283182302771855 percent\n",
      "error rate on test set =  0.8109177215189873 percent\n",
      " \n",
      "epoch= 18 \t time= 36.107653403282164 min \t lr= 0.03125 \t loss= 0.0018149974748860786 \t error= 0.01665778251599147 percent\n",
      "error rate on test set =  0.7713607594936709 percent\n",
      " \n",
      "epoch= 19 \t time= 38.16921850442886 min \t lr= 0.03125 \t loss= 0.0017603032876401883 \t error= 0.02498667377398721 percent\n",
      "error rate on test set =  0.7713607594936709 percent\n",
      " \n",
      "epoch= 20 \t time= 40.282228497664136 min \t lr= 0.015625 \t loss= 0.001599160712116449 \t error= 0.01832356076759062 percent\n",
      "error rate on test set =  0.7911392405063291 percent\n",
      " \n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "for epoch in range(1,30):\n",
    "    \n",
    "    if not epoch%5:\n",
    "        my_lr = my_lr / 2\n",
    "        \n",
    "    optimizer=torch.optim.SGD( net.parameters() , lr=my_lr )\n",
    "        \n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    \n",
    "    shuffled_indices=torch.randperm(60000)\n",
    " \n",
    "    for count in range(0,60000,bs):\n",
    "        \n",
    "        # FORWARD AND BACKWARD PASS\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "             \n",
    "        indices=shuffled_indices[count:count+bs]\n",
    "        minibatch_data =  train_data[indices].unsqueeze(dim=1)\n",
    "        minibatch_label=  train_label[indices]\n",
    "        \n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        inputs = (minibatch_data - mean)/std      \n",
    "        \n",
    "        inputs.requires_grad_()\n",
    "\n",
    "        scores=net( inputs ) \n",
    "\n",
    "        loss =  criterion( scores , minibatch_label) \n",
    "          \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # COMPUTE STATS\n",
    "        \n",
    "        running_loss += loss.detach().item()\n",
    "        \n",
    "        error = utils.get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "        \n",
    "        num_batches+=1        \n",
    "    \n",
    "    \n",
    "    # AVERAGE STATS THEN DISPLAY\n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    elapsed = (time.time()-start)/60\n",
    "    \n",
    "    print('epoch=',epoch, '\\t time=', elapsed,'min', '\\t lr=', my_lr  ,'\\t loss=', total_loss , '\\t error=', total_error*100 ,'percent')\n",
    "    eval_on_test_set() \n",
    "    print(' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
