{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01 : Convolutional layer - demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a convolutional module\n",
    "- inputs: 2 channels\n",
    "- output: 5 activation maps\n",
    "- filters are 3x3\n",
    "- padding with one layer of zero to not shrink anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = nn.Conv2d(2, 5, kernel_size = 3, padding = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an input 2 x 6 x 6 (two channels, each one has 6 x 6 pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.1800, 0.4481, 0.0222, 0.5479, 0.9021, 0.0836],\n",
      "          [0.9588, 0.5581, 0.4469, 0.6814, 0.0144, 0.1114],\n",
      "          [0.7085, 0.2309, 0.2188, 0.4994, 0.2918, 0.8046],\n",
      "          [0.2780, 0.1227, 0.8891, 0.0351, 0.6444, 0.7535],\n",
      "          [0.5478, 0.5258, 0.9977, 0.0142, 0.7971, 0.7752],\n",
      "          [0.3204, 0.0682, 0.7594, 0.8868, 0.0788, 0.4538]],\n",
      "\n",
      "         [[0.3223, 0.2892, 0.8536, 0.7549, 0.5476, 0.3034],\n",
      "          [0.9968, 0.3163, 0.0535, 0.4807, 0.7006, 0.4321],\n",
      "          [0.8208, 0.1558, 0.0807, 0.4571, 0.5831, 0.6091],\n",
      "          [0.1431, 0.6383, 0.5595, 0.5073, 0.3690, 0.1102],\n",
      "          [0.2844, 0.4439, 0.1170, 0.5130, 0.1477, 0.1951],\n",
      "          [0.1327, 0.7202, 0.6545, 0.4333, 0.1673, 0.1305]]]])\n",
      "torch.Size([1, 2, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "bs = 1\n",
    "\n",
    "x = torch.rand(bs, 2, 6, 6)\n",
    "\n",
    "print(x)\n",
    "\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed it to the convolutional layer: the output should have 5 channels (each one is 6 x 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-5.0214e-02, -1.6885e-01, -1.9739e-02, -3.2235e-01, -1.4638e-01,\n",
      "           -1.7938e-01],\n",
      "          [-7.7634e-02, -5.3847e-01, -2.0822e-01, -1.1092e-01, -8.0369e-02,\n",
      "           -2.0612e-01],\n",
      "          [-3.0847e-01, -5.2911e-05, -3.3002e-01, -1.9820e-01, -8.7496e-02,\n",
      "           -3.0322e-01],\n",
      "          [-2.1641e-01,  7.4030e-02, -3.7966e-01, -8.3681e-02, -3.4827e-01,\n",
      "           -3.2666e-01],\n",
      "          [-3.8478e-01, -6.0934e-02, -3.4827e-01, -4.5648e-02, -3.8941e-01,\n",
      "           -1.9282e-01],\n",
      "          [-2.6823e-01, -4.3397e-02, -5.0612e-01,  2.0322e-02, -2.8528e-01,\n",
      "           -2.4372e-01]],\n",
      "\n",
      "         [[-1.6191e-01, -1.2152e-01,  5.5644e-03,  4.7570e-02,  2.4619e-01,\n",
      "            5.4768e-02],\n",
      "          [ 2.9460e-01,  7.0987e-02,  2.7971e-01,  4.5939e-01, -1.0503e-02,\n",
      "           -2.1390e-01],\n",
      "          [ 4.3717e-01, -1.8726e-01, -1.0233e-01,  1.1599e-01,  2.3424e-03,\n",
      "            1.3349e-01],\n",
      "          [ 2.8979e-02, -2.5080e-01,  1.3288e-01, -3.9837e-02, -4.7513e-02,\n",
      "           -1.0693e-01],\n",
      "          [ 3.1016e-01,  2.8558e-01,  6.7151e-03, -1.1101e-02, -8.6368e-02,\n",
      "           -7.6789e-02],\n",
      "          [ 1.5406e-01,  9.8646e-02, -2.1489e-02,  2.4810e-01, -2.3264e-02,\n",
      "           -1.2383e-01]],\n",
      "\n",
      "         [[ 3.7688e-01,  1.6722e-02,  1.9286e-01,  3.3877e-01,  4.0117e-01,\n",
      "            2.3426e-02],\n",
      "          [ 5.3892e-01,  1.2594e-01,  2.5076e-01,  5.1694e-01,  5.5600e-01,\n",
      "            3.0774e-01],\n",
      "          [ 5.1062e-01,  5.6746e-01,  2.0888e-01,  4.5344e-01,  2.6577e-01,\n",
      "            2.5419e-01],\n",
      "          [ 2.9701e-01,  3.3410e-01,  3.5512e-01,  3.0963e-01,  2.5467e-01,\n",
      "            2.6476e-01],\n",
      "          [ 3.4826e-01,  4.6820e-01,  4.6366e-01,  1.6644e-01,  1.0984e-01,\n",
      "            3.1026e-01],\n",
      "          [ 1.1032e-01,  1.2559e-01,  3.1361e-01,  3.5990e-01,  1.4855e-02,\n",
      "            2.9757e-01]],\n",
      "\n",
      "         [[-1.8240e-01, -3.5402e-02,  1.5477e-01,  1.3269e-01,  1.6609e-02,\n",
      "           -1.2969e-01],\n",
      "          [-2.9604e-01, -8.3473e-02, -7.1535e-02, -2.7751e-01, -1.2598e-03,\n",
      "           -1.0410e-01],\n",
      "          [-1.8288e-01,  4.8928e-02, -3.6973e-01, -1.8029e-01,  4.7251e-02,\n",
      "            5.6361e-02],\n",
      "          [-1.6878e-01,  5.5925e-02, -1.5978e-01, -1.7756e-01, -7.5093e-02,\n",
      "           -1.7740e-01],\n",
      "          [-1.3048e-01, -1.0542e-01, -7.7015e-02, -2.4786e-01, -3.9856e-02,\n",
      "           -2.5217e-01],\n",
      "          [-4.1418e-01, -3.1674e-01, -1.3080e-01, -2.1951e-01, -3.2467e-01,\n",
      "           -2.2431e-01]],\n",
      "\n",
      "         [[-2.3053e-01, -1.5729e-01, -2.7894e-01, -1.4325e-01, -2.0442e-01,\n",
      "           -1.8029e-01],\n",
      "          [-2.4584e-01,  6.1589e-02,  3.1382e-02, -1.8793e-01, -4.0146e-01,\n",
      "           -2.1652e-01],\n",
      "          [-3.3156e-01, -1.8222e-01, -2.6862e-01, -4.0228e-01, -3.6759e-02,\n",
      "            5.7824e-02],\n",
      "          [-2.2682e-01, -2.1482e-01, -1.1208e-01, -1.9542e-01,  1.4549e-01,\n",
      "           -5.1165e-02],\n",
      "          [-2.6305e-01, -8.0029e-02, -1.4776e-02, -1.7901e-01,  7.1233e-02,\n",
      "           -2.7889e-01],\n",
      "          [-3.0389e-01, -3.7088e-01, -2.4457e-01, -1.4700e-01, -1.3869e-01,\n",
      "           -4.0058e-01]]]], grad_fn=<MkldnnConvolutionBackward>)\n",
      "torch.Size([1, 5, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "y = mod(x)\n",
    "\n",
    "print(y)\n",
    "\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the 5 filters\n",
    "- Our filters are 2x3x3\n",
    "- Each of the filter has 2 channels because the inputs have two channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.1501, -0.1803,  0.0879],\n",
      "          [ 0.1463, -0.0292, -0.1119],\n",
      "          [ 0.0211, -0.0780,  0.1634]],\n",
      "\n",
      "         [[-0.0016,  0.0037, -0.1901],\n",
      "          [-0.1811,  0.1516,  0.1060],\n",
      "          [-0.1344,  0.1357, -0.0447]]],\n",
      "\n",
      "\n",
      "        [[[-0.1410, -0.2192,  0.0304],\n",
      "          [ 0.0738,  0.1770, -0.1051],\n",
      "          [-0.0656, -0.2150, -0.1832]],\n",
      "\n",
      "         [[ 0.0678,  0.2014,  0.2044],\n",
      "          [-0.1493,  0.2258,  0.0168],\n",
      "          [-0.0076, -0.0038,  0.2195]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1619,  0.0322, -0.0492],\n",
      "          [-0.0293,  0.1560, -0.1539],\n",
      "          [ 0.0092, -0.0233,  0.0960]],\n",
      "\n",
      "         [[ 0.0538,  0.0075,  0.1085],\n",
      "          [-0.0267,  0.2116, -0.0580],\n",
      "          [-0.2115,  0.2208,  0.2294]]],\n",
      "\n",
      "\n",
      "        [[[-0.0446, -0.1556, -0.2076],\n",
      "          [-0.0482,  0.0441,  0.1045],\n",
      "          [ 0.0030, -0.0671,  0.1662]],\n",
      "\n",
      "         [[ 0.1336,  0.0812, -0.2059],\n",
      "          [ 0.1348,  0.0542, -0.0422],\n",
      "          [ 0.0877, -0.1957,  0.2332]]],\n",
      "\n",
      "\n",
      "        [[[-0.1899, -0.1574,  0.0416],\n",
      "          [ 0.0133,  0.1308,  0.1251],\n",
      "          [-0.0124,  0.1259,  0.1095]],\n",
      "\n",
      "         [[ 0.0962,  0.1344,  0.0155],\n",
      "          [ 0.2061, -0.2068, -0.1001],\n",
      "          [ 0.0316, -0.1246, -0.1159]]]], requires_grad=True)\n",
      "torch.Size([5, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(mod.weight)\n",
    "\n",
    "print(mod.weight.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
